{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120416,"status":"ok","timestamp":1720603461245,"user":{"displayName":"SALVATORE ERGOLI","userId":"14259257916772642186"},"user_tz":-120},"id":"KyyA9EkGZNCY","outputId":"d363dec1-82ed-472d-8d00-80930155834f"},"outputs":[],"source":["!pip install datasets\n","!pip install evaluate\n","!pip install transformers\n","!pip install accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19278,"status":"ok","timestamp":1720603480483,"user":{"displayName":"SALVATORE ERGOLI","userId":"14259257916772642186"},"user_tz":-120},"id":"Fh8y9P-YZrwI"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import datasets\n","import evaluate\n","import seaborn as sns\n","\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WkvcxFmIbYfS"},"outputs":[],"source":["dataset_path = 'dataset/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WwcKlBqZbmoC"},"outputs":[],"source":["df_train = pd.read_csv(dataset_path + 'training_ironita2018_anon_REV_.csv', sep = \";\")\n","df_test = pd.read_csv(dataset_path + 'test_gold_ironita2018_anon_REV_.csv', sep = \";\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xx11LdWVrVA7"},"outputs":[],"source":["df_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fW1XywWMcDaj"},"outputs":[],"source":["def create_label(dataset):\n","  irony_labels = dataset['irony'].values\n","  irony_array = np.array(irony_labels)\n","  return irony_array\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lDLc90lBq_ha"},"outputs":[],"source":["train_labels_irony = create_label(df_train)\n","test_labels_irony= create_label(df_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JtbIj-NYsn8L"},"outputs":[],"source":["len(test_labels_irony)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VD4WZssZt7rp"},"outputs":[],"source":["df_train = df_train.loc[:, ['text', 'irony']]\n","df_test = df_test.loc[:, ['text', 'irony']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sBBj98c2tc98"},"outputs":[],"source":["#conversione e suddivisione dei dati per training e validation\n","\n","train = datasets.Dataset.from_pandas(pd.DataFrame(data=df_train))\n","test = datasets.Dataset.from_pandas(pd.DataFrame(data=df_test))\n","\n","train_dev = train.train_test_split(test_size=0.1)\n","\n","train = train_dev[\"train\"]\n","dev = train_dev[\"test\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CdGPllRrt1UW"},"outputs":[],"source":["#caricamento del modello di classificazione e del tokenizer pre-addestrati\n","\n","model_name = 'osiria/distilbert-base-italian-cased'\n","\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KLvd1BNuy4qd"},"outputs":[],"source":["#tokenizzazione dei dati e conversione nel formato richiesto per Pytorch\n","\n","def tokenize(batch):\n","    tokens = tokenizer(batch['text'], padding=True, truncation=True, max_length=512)\n","    tokens['label'] = batch['irony']\n","\n","    return tokens\n","\n","train = train.map(tokenize, batched=True)\n","dev = dev.map(tokenize, batched=True)\n","test = test.map(tokenize, batched=True)\n","\n","train.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n","dev.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n","test.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"R-J0AASbzZBA"},"outputs":[],"source":["#configurazione dei parametri di addestramento per il trainer\n","\n","num_epochs = 5\n","\n","training_args = TrainingArguments(\n","    f\"{model_name}-finetuned\",\n","    evaluation_strategy = \"epoch\",\n","    logging_strategy=\"epoch\",\n","    save_strategy = \"epoch\",\n","    logging_steps=10,\n","    learning_rate=2e-6,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=num_epochs,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QGpjDRnLzgAg"},"outputs":[],"source":["#definizione della funzione per la valutazione del modello \n","\n","def compute_metrics(eval_pred):\n","  f1_metric = evaluate.load(\"f1\")\n","  predictions, labels = eval_pred\n","  predictions = np.argmax(predictions, axis=1)\n","\n","  return f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_6uA8_HYzjfS"},"outputs":[],"source":["# inizialiazzione del trainer del modello\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=train,\n","    eval_dataset=dev,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()\n","trainer.save_model(\"FINETUNED_MODEL\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pxkvj9LKhYOt"},"outputs":[],"source":["log_history = trainer.state.log_history\n","\n","df = pd.DataFrame(columns=[\"Epoch\", \"Loss\", \"Training/Validation\"])\n","\n","for log_data in log_history:\n","    epoch = int(log_data[\"epoch\"])\n","    if \"loss\" in log_data.keys():\n","        loss = log_data[\"loss\"]\n","        new_row = pd.DataFrame({\"Epoch\": [epoch], \"Loss\": [loss], \"Training/Validation\": [\"Training\"]})\n","        df = pd.concat([df, new_row], ignore_index=True)\n","    if \"eval_loss\" in log_data.keys():\n","        loss = log_data[\"eval_loss\"]\n","        new_row = pd.DataFrame({\"Epoch\": [epoch], \"Loss\": [loss], \"Training/Validation\": [\"Validation\"]})\n","        df = pd.concat([df, new_row], ignore_index=True)\n","\n","sns.lineplot(data=df, x=\"Epoch\", y=\"Loss\", hue=\"Training/Validation\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"I2GeAsVMC7Qd"},"outputs":[],"source":["output_predictions = trainer.predict(test)\n","print(output_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dQgqYVG7DhQd"},"outputs":[],"source":["y_test = test[\"label\"].tolist()\n","y_pred = np.argmax(output_predictions.predictions, axis=1)\n","\n","report = classification_report(y_test, y_pred)\n","cm = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, xticks_rotation='vertical', cmap='Blues')\n","\n","print(\"Classification Report:\")\n","print(report)\n","print()\n","\n","print(\"Confusion Matrix:\")\n","print(cm)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOuNGGzyrUTPjJ0IWv0cAU3","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
